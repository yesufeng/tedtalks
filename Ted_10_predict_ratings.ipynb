{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating prediction based on k-nearest neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script predicts ratings using similarity metrics produced by LSI, the whole analysis is on the training set, a separate script will deal with test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import unidecode\n",
    "%matplotlib inline\n",
    "import copy\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora,models,similarities\n",
    "from sklearn.cross_validation import KFold\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "from itertools import product\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load similarity matrices and ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load LSI corpuses with different num of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpustrain_lsi_50 = corpora.MmCorpus('./data/corpustrain_lsi.mm')\n",
    "corpustrain_lsi_20 = corpora.MmCorpus('./data/corpustrain_lsi_20.mm')\n",
    "corpustrain_lsi_25 = corpora.MmCorpus('./data/corpustrain_lsi_25.mm')\n",
    "corpustrain_lsi_30 = corpora.MmCorpus('./data/corpustrain_lsi_30.mm')\n",
    "corpustrain_lsi_40 = corpora.MmCorpus('./data/corpustrain_lsi_40.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpuslist = [corpustrain_lsi_20,corpustrain_lsi_25,corpustrain_lsi_30,corpustrain_lsi_40,\n",
    "             corpustrain_lsi_50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_corpustrain_lsi_50 = corpora.MmCorpus('./data/sp_corpustrain_lsi.mm')\n",
    "sp_corpustrain_lsi_20 = corpora.MmCorpus('./data/sp_corpustrain_lsi_20.mm')\n",
    "sp_corpustrain_lsi_25 = corpora.MmCorpus('./data/sp_corpustrain_lsi_25.mm')\n",
    "sp_corpustrain_lsi_30 = corpora.MmCorpus('./data/sp_corpustrain_lsi_30.mm')\n",
    "sp_corpustrain_lsi_40 = corpora.MmCorpus('./data/sp_corpustrain_lsi_40.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_corpuslist = [sp_corpustrain_lsi_20,sp_corpustrain_lsi_25,sp_corpustrain_lsi_30,\n",
    "                sp_corpustrain_lsi_40,sp_corpustrain_lsi_50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load the training dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the topic similarity, speaker_gender can be used as a baseline. There are other features stored in the captions_f.json, such as length of the talk, talking speed, num of paragraph etc., however as they are numerical values, are not incorporated into the current neighborhood based method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('train3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.sort_values(by = 'id',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1531, 33)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = list(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset = np.array(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1531"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up function to extract similar talks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iddict = dict([(item[1],item[0]) for item in ids.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowdict = dict([(item[0],item[1]) for item in ids.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def give_similar_talks(talkid,corpus,index,trainset,num_of_talks = 10):\n",
    "    \"\"\"\n",
    "    inputs: talkid,corpus,num_of_talks,index\n",
    "            trainset: a series of ids\n",
    "    outputs:\n",
    "            a list of tuples, (talkid, cosine similarity score in descending order)\n",
    "    \"\"\"\n",
    "    tmpset = set(trainset).difference(set([talkid])) # remove the target talk itself if it presents\n",
    "    sims = index[corpus[iddict[talkid]]]\n",
    "    sims = sorted(enumerate(sims),reverse = True, key = lambda x:x[1])\n",
    "    res = []\n",
    "    ctr = 0\n",
    "    for key,value in sims:\n",
    "        if rowdict[key] in tmpset:\n",
    "            res.append((rowdict[key],value))\n",
    "            ctr += 1\n",
    "        if ctr >= num_of_talks:\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(corpustrain_lsi_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_index = similarities.MatrixSimilarity(sp_corpustrain_lsi_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1672, 0.9052946),\n",
       " (1954, 0.90312833),\n",
       " (1403, 0.86130905),\n",
       " (930, 0.78333473),\n",
       " (751, 0.77572221),\n",
       " (1646, 0.7608012),\n",
       " (1120, 0.76032686),\n",
       " (704, 0.74961346),\n",
       " (2110, 0.74808681),\n",
       " (1053, 0.73183328)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_similar_talks(1666,corpustrain_lsi_50,index,ids,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### give similar talks based on speaker info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1672, 0.92408538),\n",
       " (1248, 0.81673884),\n",
       " (1954, 0.80270743),\n",
       " (1031, 0.79996693),\n",
       " (1646, 0.74974966),\n",
       " (1734, 0.73386347),\n",
       " (2152, 0.72371781),\n",
       " (1732, 0.70604813),\n",
       " (809, 0.68890679),\n",
       " (1728, 0.67879176)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_similar_talks(1666,sp_corpustrain_lsi_50,sp_index,ids,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neighborhood based model construction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is straightforward at this point, I use $\\hat Y_{i} $ to represent the estimated rating of talk i, it equals to the gender baseline ($\\bar Y_{f(m)i}$ ) plus weighted average ratings from similar talks based on topic and speaker background, the similarity between talks is denoted as $\\ s_{ij} $ , which should be a weighted similarity taking into account both the topic and speaker background info\n",
    "\n",
    "$$ \\hat{Y_{i}} = \\bar Y_{f(m)i}\\, + \\,\\frac{\\sum\\limits_{j \\in S^{k}(i)} s_{ij} ( Y_{j} - \\bar Y_{f(m)j} )}{\\sum\\limits_{j \\in S^{k}(i)} s_{ij} } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 baseline calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = train.ix[:,:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = ratings.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratingsum_raw = ratings.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### store ratingwords into a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratingwords = list(ratings.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### smooth zero counts using Dirichlet prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings[ratingwords] = ratings[ratingwords]+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### convert to proportion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = ratings[ratingwords].div(ratingsum_raw+14,axis = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings['id'] = train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings['ratesum'] = ratingsum_raw + 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calculate the overall mean vector of ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_mean = ratings[ratingwords].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calculate mean difference between male and female speakers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings['gender'] = train['speaker_gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1110\n",
       "0     421\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "female_mean = ratings.groupby('gender')[ratingwords].mean().ix[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_mean = ratings.groupby('gender')[ratingwords].mean().ix[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Prediction based on transcripts similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the simple model with gender baseline plus the weighted averaged ratings from top k similar talks. The hyperparameters are k (number of neighbors) and number of topics, tuned using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Beautiful       0.124457\n",
       "Confusing       0.003618\n",
       "Courageous      0.303907\n",
       "Fascinating     0.059334\n",
       "Funny           0.002894\n",
       "Informative     0.073082\n",
       "Ingenious       0.005065\n",
       "Inspiring       0.345876\n",
       "Jaw-dropping    0.029667\n",
       "Longwinded      0.000724\n",
       "OK              0.005065\n",
       "Obnoxious       0.002171\n",
       "Persuasive      0.040521\n",
       "Unconvincing    0.003618\n",
       "Name: 1087, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.ix[iddict[1666],ratingwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_rating1(talkid,trainset,k,corpus,index):\n",
    "    \"\"\"\n",
    "    given the target talkid, the trainset, the number of similar talks to be selected and the specific corpus with\n",
    "    selected number of topics (from: 20,25,30,40,50)\n",
    "    return the prediction as a numpy array\n",
    "    input: trainset: a numpy series talk ids\n",
    "           k: (int) number of most similar talks to retrieve,\n",
    "           corpus: the specific corpus\n",
    "           index: the corresponding index for the corpus\n",
    "    output: a numpy array of predicted rating\n",
    "    \"\"\"\n",
    "    sim_talks = give_similar_talks(talkid,corpus,index,trainset,num_of_talks=k)\n",
    "    weights_sum = sum([sim for num,sim in sim_talks])\n",
    "    # initialize rating_vect with zeros\n",
    "    rating_vect = pd.Series(0,index = female_mean.index)\n",
    "    for sim_talk_id,sim in sim_talks:\n",
    "        sim_vect = ratings.ix[iddict[sim_talk_id],ratingwords]\n",
    "        if train.ix[iddict[sim_talk_id],'speaker_gender'] == 0:\n",
    "             sim_vect -= female_mean\n",
    "        else:\n",
    "             sim_vect -= male_mean\n",
    "        rating_vect += sim_vect*sim\n",
    "    if len(sim_talks) != 0:\n",
    "        rating_vect /= weights_sum\n",
    "    else:\n",
    "        pass\n",
    "        # print 'no similar talks is found for talk with id {}, base prediction is used'.format(talkid)\n",
    "    # gender\n",
    "    gender = train.ix[iddict[talkid],'speaker_gender']\n",
    "    if gender == 0:\n",
    "        rating_vect += female_mean\n",
    "    else:\n",
    "        rating_vect += male_mean\n",
    "    # handle non-positive ratings, truncate them to be positive (0.0001)\n",
    "    rating_vect = [x if x > 0 else 0.0001 for x in rating_vect]\n",
    "    rating_vect = pd.Series(rating_vect,index = female_mean.index)\n",
    "    return rating_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_distance(vect1,vect2,dist = 'hellinger'):\n",
    "    \"\"\"\n",
    "    calculate the distance between two probability distributions\n",
    "    default type is hellinger distance, which is bounded in [0,1]\n",
    "    the other option is Jensen-shannon distance, which is also bounded in [0,1]\n",
    "    \"\"\"\n",
    "    if dist == 'hellinger':\n",
    "        return np.sqrt(0.5*sum((np.sqrt(vect1)-np.sqrt(vect2))**2))\n",
    "    if dist == 'Jensen':\n",
    "        vectq = 0.5*(vect1+vect2)\n",
    "        js_div = 0.5*sum(vect1*np.log2(vect1)+vect2*np.log2(vect2))-sum(vectq*np.log2(vectq))\n",
    "        return np.sqrt(js_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = pred_rating1(1666,ids,5,corpustrain_lsi_50,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real = ratings.ix[iddict[1666],ratingwords].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15502837986399401"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_distance(predicted,real,'Jensen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13092252335076504"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_distance(predicted,real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the range of the distance metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "talk1 = ratings.ix[iddict[1666],ratingwords].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "talk2 = ratings.ix[iddict[1],ratingwords].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57977383386720038"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_distance(talk1,talk2,'Jensen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation to tune k and number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(trainset),n_folds = 10,random_state = 321,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished within 488.677018166 sec\n"
     ]
    }
   ],
   "source": [
    "k_values = [3,5,7,10,15,20]\n",
    "num_topics = xrange(5) # this corresponds to the position of the real number of topics in the list[20,25,30,40,50]\n",
    "hypergrid = list(itertools.product(k_values,num_topics))\n",
    "difference_all = defaultdict(list)\n",
    "\n",
    "t0 = time()\n",
    "for k,numtp in hypergrid:\n",
    "    corpus = corpuslist[numtp]\n",
    "    index = similarities.MatrixSimilarity(corpus)\n",
    "    cv_difference = []\n",
    "    for train_index,test_index in kf:\n",
    "        cv_trainset,cv_testset = ids[train_index],ids[test_index]\n",
    "        # for each talk in the test set, calculate its rating based on similar talks in the cv_trainset\n",
    "        # vectorize the operation using Pandas series\n",
    "        for test_talkid in cv_testset:\n",
    "            predicted = pred_rating1(test_talkid,cv_trainset,k,corpus,index)\n",
    "            res = ratings.ix[iddict[test_talkid],ratingwords].values\n",
    "            difference = prob_distance(predicted,res,'hellinger')\n",
    "            #cv_ids.append(test_talkid)\n",
    "            #cv_predicted.append(predicted)\n",
    "            cv_difference.append(difference)\n",
    "    difference_all[(k,numtp)] = cv_difference\n",
    "print 'finished within {} sec'.format(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished within 674.507706165 sec\n"
     ]
    }
   ],
   "source": [
    "k_values = [25,30,40]\n",
    "num_topics = xrange(5) # this corresponds to the position of the real number of topics in the list[20,25,30,40,50]\n",
    "hypergrid2 = list(itertools.product(k_values,num_topics))\n",
    "\n",
    "t0 = time()\n",
    "for k,numtp in hypergrid2:\n",
    "    corpus = corpuslist[numtp]\n",
    "    index = similarities.MatrixSimilarity(corpus)\n",
    "    cv_difference = []\n",
    "    for train_index,test_index in kf:\n",
    "        cv_trainset,cv_testset = ids[train_index],ids[test_index]\n",
    "        # for each talk in the test set, calculate its rating based on similar talks in the cv_trainset\n",
    "        # vectorize the operation using Pandas series\n",
    "        for test_talkid in cv_testset:\n",
    "            predicted = pred_rating1(test_talkid,cv_trainset,k,corpus,index)\n",
    "            res = ratings.ix[iddict[test_talkid],ratingwords].values\n",
    "            difference = prob_distance(predicted,res,'hellinger')\n",
    "            #cv_ids.append(test_talkid)\n",
    "            #cv_predicted.append(predicted)\n",
    "            cv_difference.append(difference)\n",
    "    difference_all[(k,numtp)] = cv_difference\n",
    "print 'finished within {} sec'.format(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_all_list = []\n",
    "for key in difference_all.keys():\n",
    "    meandiff = sum(difference_all[key])/len(difference_all[key])\n",
    "    difference_all_list.append((key,meandiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((20, 3), 0.23282784472626136),\n",
       " ((25, 3), 0.23322648903218504),\n",
       " ((15, 3), 0.23324181502479852),\n",
       " ((20, 0), 0.23346633430196487),\n",
       " ((30, 3), 0.2335714637784439),\n",
       " ((20, 4), 0.23382919050147546),\n",
       " ((20, 2), 0.23391249995759031),\n",
       " ((15, 0), 0.23397947158566559),\n",
       " ((25, 4), 0.23405848246848254),\n",
       " ((25, 2), 0.23406105547148157)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(difference_all_list,key = lambda x:x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted1 = pred_rating1(129,ids,20,corpustrain_lsi_40,similarities.MatrixSimilarity(corpustrain_lsi_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real1 = ratings.ix[iddict[129],ratingwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49522970379890707"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_distance(predicted1,real1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "1. Multiple pairs of hyperparameters reached the same prediction accuracy, measured by mean hellinger distance, around 0.23\n",
    "2. prediction on talk 129 is very far off, and this is revealing and captures the shortcoming of this neighborhood based prediction. the extreme distribution of the ratings this talk received: more than 70% ratings are 'jaw-dropping' is very different from all its neighbors (in the topic space).\n",
    "4. move on to combine speaker similarity, which shows high similarity scores for talks that don't have very similar talk in the transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Combined similarity of talk topic and speaker background "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General ideas:\n",
    "1. define k_trans and k_sp (the threshold for similar talks) separately, so that they can be tuned separately.\n",
    "2. the final similarity would be a weighted version of both similarities in ideal cases where both similarities are found. \n",
    "3. if only one exists, use that one, if neither exists, use baseline prediction\n",
    "4. how to select talks: first implementation, use the two k's to find two lists, take the union and find all similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def give_similarities(talkid, corpus,index,similar_talks):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    similar_talks is the list of talk ids that are from the other topic modeling results (e.g., similar\n",
    "    speaker), but not contained in the current topic modeling (similar topics) results of most similar talks\n",
    "    \n",
    "    outputs:\n",
    "    return a list of tuples, (talkid, cosine similarity score), the list is not sorted on similarity score\n",
    "    \"\"\"\n",
    "    tmpset = set(trainset)\n",
    "    tmpset.remove(talkid) # remove the target talk itself if it presents\n",
    "    sims = index[corpus[iddict[talkid]]]\n",
    "    # sims = sorted(enumerate(sims),reverse = True, key = lambda x:x[1])\n",
    "    # sims_id = [(rowdict[key],value) for key,value in sims]\n",
    "    sim_dict = dict([(rowdict[ind],value) for ind,value in enumerate(sims)])\n",
    "    res = [(tid,sim_dict[tid]) for tid in similar_talks]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Steps:\n",
    "1. use give_similar_talks to find similar talks based on transcript and speaker background.\n",
    "2. make a union of the two lists. Several logics here: if both found, merge, if none, baseline, if one, use the only one\n",
    "3. if both lists exist, we need to find both similarities for all talks in the united list, using give_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_similar_talks(talkid,num_trans,num_sp,trainset,corpus,index,sp_corpus,sp_index):\n",
    "    \"\"\"\n",
    "    inputs: num_trans -- num of similar talks based on transcripts\n",
    "            num_sp -- num of similar talks based on speaker background info\n",
    "            trainset -- may not be the complete training set, e.g., in CV\n",
    "            corpus, index\n",
    "    outputs:\n",
    "            sim_talks -- the same output as give_similar_talks, a list of tuples (talkid, final_sim_score)\n",
    "    \"\"\"\n",
    "    #1. find sim talks based on trans and sp\n",
    "    sim_talks_trans = give_similar_talks(talkid,corpus,index,trainset,\n",
    "                                         num_of_talks=num_trans)\n",
    "    sim_talks_sp = give_similar_talks(talkid,sp_corpus,sp_index,trainset,\n",
    "                                      num_of_talks=num_sp)\n",
    "    #2. generate a combined list of similar talks\n",
    "\n",
    "    # (1). determine the relationship of the two lists(sets), find the extra similarities, and append to the lists\n",
    "    trans_set = set([x for x,y in sim_talks_trans])\n",
    "    sp_set = set([x for x,y in sim_talks_sp])\n",
    "    if sp_set.issubset(trans_set):\n",
    "        # speaker set is a subset of trans_set, then find the speaker similarities for the talks that are in the\n",
    "        # trans set but not in the speaker set\n",
    "        extra_sim_talks_sp = give_similarities(talkid,sp_corpus,sp_index,\n",
    "                                               list(trans_set.difference(sp_set)))\n",
    "        # merge the extra into the original sim_talks_sp list\n",
    "        sim_talks_sp.extend(extra_sim_talks_sp)\n",
    "    elif sp_set.issuperset(trans_set):\n",
    "        extra_sim_talks_trans = give_similarities(talkid,corpus,index,\n",
    "                                                 list(sp_set.difference(trans_set)))\n",
    "        sim_talks_trans.extend(extra_sim_talks_trans)\n",
    "    else:\n",
    "        sp_extra = list(sp_set.difference(trans_set))\n",
    "        trans_extra = list(trans_set.difference(sp_set))\n",
    "        # find both\n",
    "        extra_sim_talks_trans = give_similarities(talkid,corpus,index,sp_extra)\n",
    "        extra_sim_talks_sp = give_similarities(talkid,sp_corpus,sp_index,trans_extra)\n",
    "        # extend to the original lists\n",
    "        sim_talks_sp.extend(extra_sim_talks_sp)\n",
    "        sim_talks_trans.extend(extra_sim_talks_trans)\n",
    "    # 2. weight the two similarities to generate the final similarity score\n",
    "    ## convert the two lists into dictionaries\n",
    "    dict_talks_sp = dict(sim_talks_sp)\n",
    "    dict_talks_trans = dict(sim_talks_trans)\n",
    "    sim_talks = []\n",
    "    for key in dict_talks_sp:\n",
    "        # other weighting functions are not implemented yet!\n",
    "        sim_talks.append((key,(dict_talks_sp[key]+dict_talks_trans[key])/2.))\n",
    "\n",
    "    sim_talks.sort(reverse = True,key = lambda x:x[1])\n",
    "    return sim_talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "combine_similar_talks gives a final list of tuples (talkid, similarity score), now we need a prediction function to predict the rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_rating2(talkid,trainset,num_trans,num_sp,corpus,index,sp_corpus,sp_index):\n",
    "    \"\"\"\n",
    "    given the target talkid, the trainset and the two k values\n",
    "    return the prediction as a numpy array\n",
    "    input: trainset: a numpy array of training set talk ids \n",
    "           num_trans: k for transcript similarity\n",
    "           num_sp: k for speaker background similarity\n",
    "           corpus,index\n",
    "           sp_corpus,sp_index\n",
    "    output: a numpy array of predicted rating\n",
    "    \"\"\"\n",
    "    sim_talks = combine_similar_talks(talkid,num_trans,num_sp,trainset,corpus,index,sp_corpus,sp_index)\n",
    "    weights_sum = sum([sim for num,sim in sim_talks])\n",
    "    # initialize rating_vect with zeros\n",
    "    rating_vect = pd.Series(0,index = female_mean.index)\n",
    "    for sim_talk_id,sim in sim_talks:\n",
    "        sim_vect = ratings.ix[iddict[sim_talk_id],ratingwords]\n",
    "        if train.ix[iddict[sim_talk_id],'speaker_gender'] == 0:\n",
    "             sim_vect -= female_mean\n",
    "        else:\n",
    "             sim_vect -= male_mean\n",
    "        rating_vect += sim_vect*sim\n",
    "    if len(sim_talks) > 0:\n",
    "        rating_vect /= weights_sum\n",
    "    else:\n",
    "        pass\n",
    "        # print 'no similar talks is found for talk with id {}, base prediction is used'.format(talkid)\n",
    "    # gender\n",
    "    gender = train.ix[iddict[talkid],'speaker_gender']\n",
    "    if gender == 0:\n",
    "        rating_vect += female_mean\n",
    "    else:\n",
    "        rating_vect += male_mean\n",
    "    # handle non-positive ratings, truncate them to be positive (0.0001)\n",
    "    rating_vect = [x if x > 0 else 0.0001 for x in rating_vect]\n",
    "    rating_vect = pd.Series(rating_vect,index = female_mean.index)\n",
    "    return rating_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_trans_values = [10,15,20,25]\n",
    "k_sp_values = [5,10,15,20]\n",
    "num_topics = xrange(3,4) # fixed the num of topics in transcript to be 40\n",
    "num_topics_sp = xrange(5)\n",
    "hypergrid3 = list(product(k_trans_values,k_sp_values,num_topics,num_topics_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the fitting of 1th hyperparameter combination\n",
      "starting the fitting of 2th hyperparameter combination\n",
      "starting the fitting of 3th hyperparameter combination\n",
      "starting the fitting of 4th hyperparameter combination\n",
      "starting the fitting of 5th hyperparameter combination\n",
      "starting the fitting of 6th hyperparameter combination\n",
      "starting the fitting of 7th hyperparameter combination\n",
      "starting the fitting of 8th hyperparameter combination\n",
      "starting the fitting of 9th hyperparameter combination\n",
      "starting the fitting of 10th hyperparameter combination\n",
      "starting the fitting of 11th hyperparameter combination\n",
      "starting the fitting of 12th hyperparameter combination\n",
      "starting the fitting of 13th hyperparameter combination\n",
      "starting the fitting of 14th hyperparameter combination\n",
      "starting the fitting of 15th hyperparameter combination\n",
      "starting the fitting of 16th hyperparameter combination\n",
      "starting the fitting of 17th hyperparameter combination\n",
      "starting the fitting of 18th hyperparameter combination\n",
      "starting the fitting of 19th hyperparameter combination\n",
      "starting the fitting of 20th hyperparameter combination\n",
      "starting the fitting of 21th hyperparameter combination\n",
      "starting the fitting of 22th hyperparameter combination\n",
      "starting the fitting of 23th hyperparameter combination\n",
      "starting the fitting of 24th hyperparameter combination\n",
      "starting the fitting of 25th hyperparameter combination\n",
      "starting the fitting of 26th hyperparameter combination\n",
      "starting the fitting of 27th hyperparameter combination\n",
      "starting the fitting of 28th hyperparameter combination\n",
      "starting the fitting of 29th hyperparameter combination\n",
      "starting the fitting of 30th hyperparameter combination\n",
      "starting the fitting of 31th hyperparameter combination\n",
      "starting the fitting of 32th hyperparameter combination\n",
      "starting the fitting of 33th hyperparameter combination\n",
      "starting the fitting of 34th hyperparameter combination\n",
      "starting the fitting of 35th hyperparameter combination\n",
      "starting the fitting of 36th hyperparameter combination\n",
      "starting the fitting of 37th hyperparameter combination\n",
      "starting the fitting of 38th hyperparameter combination\n",
      "starting the fitting of 39th hyperparameter combination\n",
      "starting the fitting of 40th hyperparameter combination\n",
      "starting the fitting of 41th hyperparameter combination\n",
      "starting the fitting of 42th hyperparameter combination\n",
      "starting the fitting of 43th hyperparameter combination\n",
      "starting the fitting of 44th hyperparameter combination\n",
      "starting the fitting of 45th hyperparameter combination\n",
      "starting the fitting of 46th hyperparameter combination\n",
      "starting the fitting of 47th hyperparameter combination\n",
      "starting the fitting of 48th hyperparameter combination\n",
      "starting the fitting of 49th hyperparameter combination\n",
      "starting the fitting of 50th hyperparameter combination\n",
      "starting the fitting of 51th hyperparameter combination\n",
      "starting the fitting of 52th hyperparameter combination\n",
      "starting the fitting of 53th hyperparameter combination\n",
      "starting the fitting of 54th hyperparameter combination\n",
      "starting the fitting of 55th hyperparameter combination\n",
      "starting the fitting of 56th hyperparameter combination\n",
      "starting the fitting of 57th hyperparameter combination\n",
      "starting the fitting of 58th hyperparameter combination\n",
      "starting the fitting of 59th hyperparameter combination\n",
      "starting the fitting of 60th hyperparameter combination\n",
      "starting the fitting of 61th hyperparameter combination\n",
      "starting the fitting of 62th hyperparameter combination\n",
      "starting the fitting of 63th hyperparameter combination\n",
      "starting the fitting of 64th hyperparameter combination\n",
      "starting the fitting of 65th hyperparameter combination\n",
      "starting the fitting of 66th hyperparameter combination\n",
      "starting the fitting of 67th hyperparameter combination\n",
      "starting the fitting of 68th hyperparameter combination\n",
      "starting the fitting of 69th hyperparameter combination\n",
      "starting the fitting of 70th hyperparameter combination\n",
      "starting the fitting of 71th hyperparameter combination\n",
      "starting the fitting of 72th hyperparameter combination\n",
      "starting the fitting of 73th hyperparameter combination\n",
      "starting the fitting of 74th hyperparameter combination\n",
      "starting the fitting of 75th hyperparameter combination\n",
      "starting the fitting of 76th hyperparameter combination\n",
      "starting the fitting of 77th hyperparameter combination\n",
      "starting the fitting of 78th hyperparameter combination\n",
      "starting the fitting of 79th hyperparameter combination\n",
      "starting the fitting of 80th hyperparameter combination\n",
      "done in 3375.27665806 sec\n"
     ]
    }
   ],
   "source": [
    "difference_all3 = defaultdict(list)\n",
    "t0 = time()\n",
    "ctr = 1\n",
    "for num_trans,num_sp,numtp1,numtp2 in hypergrid3:\n",
    "    print 'starting the fitting of {}th hyperparameter combination'.format(ctr)\n",
    "    corpus = corpuslist[numtp1]\n",
    "    sp_corpus = sp_corpuslist[numtp2]\n",
    "    index = similarities.MatrixSimilarity(corpus)\n",
    "    sp_index = similarities.MatrixSimilarity(sp_corpus)\n",
    "    cv_difference = []\n",
    "    for train_index,test_index in kf:\n",
    "        cv_trainset,cv_testset = ids[train_index],ids[test_index]\n",
    "        # for each talk in the test set, calculate its rating based on similar talks in the cv_trainset\n",
    "        for test_talkid in cv_testset:\n",
    "            predicted = pred_rating2(test_talkid,cv_trainset,num_trans,num_sp,corpus,index,sp_corpus,sp_index)\n",
    "            res = ratings.ix[iddict[test_talkid],ratingwords].values\n",
    "            difference = prob_distance(predicted,res,'hellinger')\n",
    "            cv_difference.append(difference)\n",
    "    difference_all3[(num_trans,num_sp,numtp1,numtp2)] = cv_difference\n",
    "    ctr += 1\n",
    "print 'done in {} sec'.format(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(difference_all3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_all3_list = []\n",
    "for key in difference_all3:\n",
    "    meandiff = sum(difference_all3[key])/1531\n",
    "    difference_all3_list.append((key,meandiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((10, 5, 3, 4), 0.22739365015872792),\n",
       " ((15, 5, 3, 4), 0.22748253413277145),\n",
       " ((10, 5, 3, 0), 0.22756913820585403),\n",
       " ((10, 5, 3, 1), 0.22762983083885924),\n",
       " ((15, 5, 3, 1), 0.22769261639083227),\n",
       " ((15, 5, 3, 0), 0.22773037472054936),\n",
       " ((15, 5, 3, 2), 0.22790654918867437),\n",
       " ((10, 5, 3, 2), 0.22795633208927779),\n",
       " ((20, 5, 3, 4), 0.2279695916690628),\n",
       " ((20, 5, 3, 1), 0.22809766013817681)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(difference_all3_list,key = lambda x:x[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k_trans = 10, k_sp = 5ï¼Œ40 topics for transcripts and 50 topics for speaker backgrounds gives the best CV results: mean hellinger distance is 0.227"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark the training error: How much variation in rating can be explained by topics variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the optimized model to fit the complete training set and then we use the global mean to predict and compare the error against the training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_error = pd.Series(index = ids.values)\n",
    "avg_difference = pd.Series(index = ids.values)\n",
    "index_final = similarities.MatrixSimilarity(corpustrain_lsi_40)\n",
    "sp_index_final = similarities.MatrixSimilarity(sp_corpustrain_lsi_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for talkid in ids:\n",
    "    res = ratings.ix[iddict[talkid],ratingwords]\n",
    "    predicted = pred_rating2(talkid,ids,10,5,corpustrain_lsi_40,index_final,sp_corpustrain_lsi_50,sp_index_final)\n",
    "    avg_difference[talkid] = prob_distance(res,global_mean)\n",
    "    training_error[talkid] = prob_distance(res,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2907094699920077"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_difference.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22670899185439747"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x124bf2490>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAFICAYAAAC4Fzw3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUREupgKvYiISBdToRcREeli/x9FhqhWvwu0+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124b8aad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (8,5))\n",
    "ax = plt.gca()\n",
    "avg_difference.hist(bins = 30,alpha = 0.3, label = 'total error',ax = ax)\n",
    "training_error.hist(bins = 30,alpha = 0.5, label = 'training error', ax = ax)\n",
    "ax.legend(loc = 'best',fontsize = 'medium')\n",
    "plt.xlabel('Error measured by Hellinger distance to the real ratings')\n",
    "plt.ylabel('Number of talks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "1. Some moderate amount of rating variations are explained by the topic differences among talks, as shown in the above figure and by comparing the mean training error from the model (0.23) vs the total error (0.29) if estimation is made using the global mean rating vector.\n",
    "2. Evidently, a large portion of the rating variations are unexplained by a simple topic model. Outliers such as talk 129, which received predominantly one rating word: Jaw-dropping, may not be uncommon. Features that reflect other aspects of the talks, such as delivery skills may boost the prediction power.\n",
    "3. Prediction on the test set is done in a separate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
