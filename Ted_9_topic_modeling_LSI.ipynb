{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook does the LSI topic modeling on the training data set, number of topics is the key parameter and was varied and different models and corpuses were saved for prediction of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import unidecode\n",
    "%matplotlib inline\n",
    "import copy\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora,models,similarities\n",
    "from gensim.utils import lemmatize\n",
    "from string import punctuation\n",
    "from spacy.parts_of_speech import ADV, NOUN, ADJ, PUNCT, VERB\n",
    "from spacy.en import English,STOPWORDS\n",
    "from spacy.orth import *\n",
    "import logging\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from HTMLParser import HTMLParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in caption and ratings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load in captions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions = pd.read_json('captions_f.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "captions.sort_values(by = 'id',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'And_so_total', u'app_as_para', u'app_total_log', u'applause_per_word',\n",
       "       u'applause_total', u'div_per_word', u'diversion', u'funny_binary',\n",
       "       u'id', u'ithinks', u'label', u'laugh_as_para', u'laughter_per_word',\n",
       "       u'laughter_total', u'length', u'neg_binary', u'noun_token', u'num_para',\n",
       "       u'para_length', u'stopwords_ratio', u'storywords', u'text',\n",
       "       u'verb_token', u'word_per_sec', u'wordcounts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1535, 25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Drop the talks that have essentially no captions\n",
    "These talks are musical performances but have the transcript field filled in the online database. to_drop_ind = [99,1156,1464,2147], they have only place-holders such as (applause) etc in the caption field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get the row indices of these four talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_drop_ind = [99,1156,1464,2147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_drop_rows = [captions[captions.id == x].index.values[0] for x in to_drop_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75, 736, 948, 1460]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions.drop(captions.index[to_drop_rows],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save to json file captions_f3.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions.to_json('captions_f3.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### make two dictionaries: iddict {id: row_number} and rowdict (row_num: id} to convert between row and talkids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = captions.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iddict = dict([(item[1],int(item[0])) for item in ids.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowdict = dict([(item[0],item[1]) for item in ids.iteritems()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenize the text with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 remove stopwords, POS tagging and lemmatize, keep only nouns and verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantages of spaCy over NLTK are obvious, speed in tagging, and also spaCy accomplishes lemma, tagging altogether in one operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text,islist = True):\n",
    "    \"\"\"\n",
    "    This converts text to tokens, keeps only tokens \n",
    "    that are identified using coarse pos: noun and verb\n",
    "    in: text -- default to be list of lines of transcript\n",
    "        can also be a string\n",
    "    www.ling.uppen.edu/courses/Fall_2003/ling001/penn_treebank_pos\n",
    "    out:\n",
    "        list of tokens\n",
    "    \"\"\"\n",
    "    if islist:\n",
    "        text = ' '.join(text)\n",
    "    # remove '(Laughter)' etc, \n",
    "    text = re.sub('\\([\\w\\s]+\\)','',text)\n",
    "    doc = nlp(text, parse = False)\n",
    "    words = []\n",
    "    for token in doc:\n",
    "        # remove all tokens other than verbs and nouns\n",
    "        if token.pos == NOUN or token.pos == VERB:\n",
    "        # if token.tag_ in selected_tags:\n",
    "            words.append(token)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = captions.text.apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1531,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lemma(token_list):\n",
    "    # remove stopwords\n",
    "    lemmalist = []\n",
    "    for token in token_list:\n",
    "        if token.lemma_ not in STOPWORDS and len(token.lemma_) > 1:\n",
    "            lemmalist.append(token.lemma_)\n",
    "    return lemmalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens_final = tokens.apply(get_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram = models.Phrases(tokens_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save the bigram object for the transformation on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram.save('./data/bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram = models.Phrases.load('./data/bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_phrase_final = list(tokens_final.apply(lambda x:bigram[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 generate dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(token_phrase_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### filter out low and high frequency tokens using dictionary of gensim, tuning is not done yet on the threholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below = 10, no_above = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.save('./data/tedtrain.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(6129 unique tokens: [u'yellow', u'circuitry', u'centimeter', u'aggression', u'payoff']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to see mapping between words and their ids\n",
    "# print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load('./data/tedtrain.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 generate corpus using Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus is generated using dictionary.doc2bow(text), each output of this function is a list of tuples, showing the (word id,number of occurence) in the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpustrain = [dictionary.doc2bow(text) for text in token_phrase_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save the corpus to disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('./data/corpustrain.mm',corpustrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Tf-idf conversion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpustrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform the corpus using tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpustrain_idf = tfidf[corpustrain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save both the transformed corpus and the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf.save('./data/tfidf.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('./data/corpustrain_idf.mm',corpustrain_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  load the tfidf corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpustrain_idf = corpora.MmCorpus('./data/corpustrain_idf.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 LSI model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saved model and corpus are trained using 50 topics and power_iters = 50, different num of topics (20, 100, 150) are tested afterwards and evaluated by manually checking the similarity of extracted similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpustrain_idf,id2word=dictionary,num_topics=50,onepass=False,power_iters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform corpus\n",
    "corpustrain_lsi = lsi[corpustrain_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_topic_doc(projection,ids,num_top_topics,talkid = True):\n",
    "    \"\"\"\n",
    "    print the most relevant topics for the chosen documents\n",
    "    either row id or talkid can be used as input\n",
    "    \"\"\"\n",
    "    if talkid:\n",
    "        rowids = [iddict[x] for x in ids]\n",
    "    else:\n",
    "        rowids = ids\n",
    "    for ctr in xrange(len(rowids)):\n",
    "        proj = projection[rowids[ctr]]\n",
    "        proj.sort(reverse = True, key = lambda x:abs(x[1]))\n",
    "        print 'The top {} topics of the {}th document'.format(num_top_topics,rowids[ctr])\n",
    "        if talkid:\n",
    "            print 'The talk id is {}'.format(ids[ctr])\n",
    "        print proj[:num_top_topics]\n",
    "        print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 topics of the 451th document\n",
      "The talk id is 704\n",
      "[(0, 0.20301381285420877), (1, 0.17764133715921016), (12, -0.11135815262498935), (33, 0.10613426473345948), (4, 0.08559800199831194)]\n",
      "\n",
      "The top 5 topics of the 1087th document\n",
      "The talk id is 1666\n",
      "[(1, 0.24595700249439217), (0, 0.18916414006982193), (12, -0.11931160688132941), (33, 0.11351690565191623), (7, -0.10664128738445322)]\n",
      "\n",
      "The top 5 topics of the 1091th document\n",
      "The talk id is 1672\n",
      "[(1, 0.28528924821672114), (0, 0.26398507354989315), (12, -0.22064837724483552), (33, 0.2114417701333349), (7, -0.15362329281039333)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topic_doc(corpustrain_lsi,[704,1666,1672],5,talkid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test similarity measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(corpustrain_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index.save('./data/trainsim.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity.load('./data/trainsim.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def give_similar_talks(talkid, num_of_talks,corpus,index):\n",
    "    \"\"\"\n",
    "    return a list of tuples, (talkid, cosine similarity score in descending order)\n",
    "    \"\"\"\n",
    "    sims = index[corpus[iddict[talkid]]]\n",
    "    sims = sorted(enumerate(sims),reverse = True, key = lambda x:x[1])\n",
    "    sims_id = [(rowdict[key],value) for key,value in sims if rowdict[key] != talkid]\n",
    "    return sims_id[:num_of_talks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simsids = give_similar_talks(1666,5,corpustrain_lsi,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1672, 0.9052946),\n",
       " (1954, 0.90312833),\n",
       " (1403, 0.86130905),\n",
       " (930, 0.78333473),\n",
       " (751, 0.77572221)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simsids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model and transformed corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsi.save('./data/lsi.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('./data/corpustrain_lsi.mm',corpustrain_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load the model and corpus of LSI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpustrain_lsi = corpora.MmCorpus('./data/corpustrain_lsi.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsi = models.LsiModel.load('./data/lsi.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI with varied number of topics for later rating prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend is clear, with increased number of topics, cosine similarity between talks drops due to higher dimension, also, a coherent topic such as \"Afghanistan, women, education\" can be separated into \"Afghanistan\" and \"women, education\", therefore, similar in one topic dimension versus another happens more often. For now, set number to 50 (topics), seems to work very well by manually comparing the talks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topicsnos = [20,25,30,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simtalks1666 = defaultdict(list)\n",
    "simtalks129 = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 17s, sys: 1.46 s, total: 2min 19s\n",
      "Wall time: 1min 30s\n",
      "CPU times: user 2min 24s, sys: 3.36 s, total: 2min 27s\n",
      "Wall time: 1min 41s\n",
      "CPU times: user 2min 25s, sys: 3.07 s, total: 2min 28s\n",
      "Wall time: 1min 41s\n",
      "CPU times: user 2min 25s, sys: 3.04 s, total: 2min 28s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "corpuslist = []\n",
    "lsimodellist = []\n",
    "for i in xrange(len(topicsnos)):\n",
    "    num = topicsnos[i]\n",
    "    %time lsitmp = models.LsiModel(corpustrain_idf,id2word=dictionary,num_topics=num,onepass=False,power_iters=50)\n",
    "    corpus_tmp = lsitmp[corpustrain_idf]\n",
    "    corpuslist.append(corpus_tmp)\n",
    "    lsimodellist.append(lsitmp)\n",
    "    index_tmp = similarities.MatrixSimilarity(corpus_tmp)\n",
    "    simsid129 = give_similar_talks(129,5,corpus_tmp,index_tmp)\n",
    "    simsid1666 = give_similar_talks(1666,5,corpus_tmp,index_tmp)\n",
    "    simtalks1666[i] = simsid1666\n",
    "    simtalks129[i] = simsid129"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save all models for  rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(4):\n",
    "    lsi_tmp = lsimodellist[i]\n",
    "    corpustrain_tmp = corpuslist[i]\n",
    "    modelpath = './data/lsi_'+str(topicsnos[i])+'.model'\n",
    "    corpuspath = './data/corpustrain_lsi_'+str(topicsnos[i])+'.mm'\n",
    "    lsi_tmp.save(modelpath)\n",
    "    corpora.MmCorpus.serialize(corpuspath,corpustrain_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Topic modeling on the speakers background info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Construct speaker_background df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "speaker background info has actually not been used so far except extration of gender and one_speaker features. The description texts (why listen + whotheyare + description) will be used here to profile speakers and test their similarities.\n",
    "speaker info will be queried using joined train3.json and speakers.json, speakerids are from train3.json (later also for test2.json) then, texts will be found using speakerid in the speakers.json dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speakers = pd.read_json('speakers.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "speakers.sort_values(by = 'id',inplace = True)\n",
    "speakers.set_index('id',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize parser as an object\n",
    "parser = HTMLParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function to get speakers text info given speakers ids\n",
    "def speakerinfo(ids):\n",
    "    # ids is a list of ids, could be multiple speakers\n",
    "    background = ''\n",
    "    for speakerid in ids:\n",
    "        text = ' '.join([speakers.ix[speakerid,'whylisten'], speakers.ix[speakerid,'whotheyare'], \n",
    "                speakers.ix[speakerid,'description']])\n",
    "        text = parser.unescape(text)\n",
    "        background += text\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('train3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.sort_values(by = 'id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True,drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "background = train['speaker_ids'].apply(speakerinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "speaker_background = pd.DataFrame({'talk_id':train['id'],'background':background})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2  Tokenize the background text with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_tokens = background.apply(tokenize,islist = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_tokens_final = sp_tokens.apply(get_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_bigram = models.Phrases(sp_tokens_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sp_bigram.save('./data/spbigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_phrase_final = list(sp_tokens_final.apply(lambda x:sp_bigram[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Gensim: bag-of-words, Tf-idf, LSI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### generate dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_dictionary = corpora.Dictionary(sp_phrase_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out extreme tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_dictionary.filter_extremes(no_below = 5, no_above= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(3517 unique tokens: [u'similarity', u'consumer_product', u'dynamic', u'protest', u'circuitry']...)\n"
     ]
    }
   ],
   "source": [
    "print(sp_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### bag-of-word corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_corpustrain = [sp_dictionary.doc2bow(text) for text in sp_phrase_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_tfidf = models.TfidfModel(sp_corpustrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_corpustrain_idf = sp_tfidf[sp_corpustrain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI with 50 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_lsi = models.LsiModel(sp_corpustrain_idf,num_topics=50,id2word=sp_dictionary,onepass=False,power_iters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_corpustrain_lsi = sp_lsi[sp_corpustrain_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sp_lsi = models.LsiModel.load('./data/sp_lsi.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 topics of the 1087th document\n",
      "The talk id is 1666\n",
      "[(0, 0.19789349354688271), (11, 0.18850143764664773), (3, 0.1763222265014539), (7, -0.17021699336657289), (2, 0.16229029980375462), (1, -0.11404248218845903), (5, 0.10910371094620626), (10, -0.091794627838949816), (6, -0.088572105022443767), (8, -0.087870993730281718)]\n",
      "\n",
      "The top 10 topics of the 1091th document\n",
      "The talk id is 1672\n",
      "[(7, -0.15442791297992023), (0, 0.14389649481781347), (11, 0.14036567467480679), (2, 0.12849015123931395), (16, -0.097773306861731774), (10, -0.094912212800507254), (20, 0.088718770404556474), (25, -0.074969210588709936), (1, -0.07407779413334907), (37, 0.07393693318155832)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topic_doc(sp_corpustrain_lsi,[1666,1672],10,talkid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### example of similar speaker profile extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_index = similarities.MatrixSimilarity(sp_corpustrain_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_index.save('./data/sp_trainsim.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_index = similarities.MatrixSimilarity.load('./data/sp_trainsim.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_simlist = give_similar_talks(152,5,sp_corpustrain_lsi,sp_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(127, 1.0),\n",
       " (1321, 0.85291243),\n",
       " (1851, 0.81708348),\n",
       " (1842, 0.80890816),\n",
       " (2105, 0.77260721)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_simlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save all models and corpus of speaker background "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_lsi.save('./data/sp_lsi.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('./data/sp_corpustrain_lsi.mm',sp_corpustrain_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_tfidf.save('./data/sp_tfidf.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('./data/sp_corpustrain_idf.mm',sp_corpustrain_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_dictionary.save('./data/sp_train.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('./data/sp_tedtrain.mm',sp_corpustrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speaker topic modeling LSI with varied number of topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_simtalks1666 = defaultdict(list)\n",
    "sp_simtalks129 = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.5 s, sys: 579 ms, total: 33.1 s\n",
      "Wall time: 8.49 s\n",
      "CPU times: user 32.6 s, sys: 505 ms, total: 33.2 s\n",
      "Wall time: 8.37 s\n",
      "CPU times: user 32.4 s, sys: 1.26 s, total: 33.6 s\n",
      "Wall time: 8.75 s\n",
      "CPU times: user 35.2 s, sys: 1.2 s, total: 36.4 s\n",
      "Wall time: 9.5 s\n"
     ]
    }
   ],
   "source": [
    "sp_corpuslist = []\n",
    "sp_lsimodellist = []\n",
    "for i in xrange(len(topicsnos)):\n",
    "    num = topicsnos[i]\n",
    "    %time sp_lsitmp = models.LsiModel(sp_corpustrain_idf,id2word=sp_dictionary,num_topics=num,onepass=False,power_iters=50)\n",
    "    sp_corpus_tmp = sp_lsitmp[sp_corpustrain_idf]\n",
    "    sp_corpuslist.append(sp_corpus_tmp)\n",
    "    sp_lsimodellist.append(sp_lsitmp)\n",
    "    sp_index_tmp = similarities.MatrixSimilarity(sp_corpus_tmp)\n",
    "    sp_simsid129 = give_similar_talks(129,5,sp_corpus_tmp,sp_index_tmp)\n",
    "    sp_simsid1666 = give_similar_talks(1666,5,sp_corpus_tmp,sp_index_tmp)\n",
    "    sp_simtalks1666[i] = sp_simsid1666\n",
    "    sp_simtalks129[i] = sp_simsid129"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save all models for rating predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(4):\n",
    "    sp_lsi_tmp = sp_lsimodellist[i]\n",
    "    sp_corpustrain_tmp = sp_corpuslist[i]\n",
    "    modelpath = './data/sp_lsi_'+str(topicsnos[i])+'.model'\n",
    "    corpuspath = './data/sp_corpustrain_lsi_'+str(topicsnos[i])+'.mm'\n",
    "    sp_lsi_tmp.save(modelpath)\n",
    "    corpora.MmCorpus.serialize(corpuspath,sp_corpustrain_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of transcripts and speaker background topic modeling (similarities) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test speaker similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_corpustrain_lsi = corpora.MmCorpus('./data/sp_corpustrain_lsi.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_index = similarities.MatrixSimilarity(sp_corpustrain_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "give a talk id, find the most similar speakers to the speaker of this talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_simlist = give_similar_talks(1666,5,sp_corpustrain_lsi,sp_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1672, 0.92408538),\n",
       " (1248, 0.81673884),\n",
       " (1954, 0.80270743),\n",
       " (1031, 0.79996693),\n",
       " (1646, 0.74974966)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_simlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test transcripts similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpustrain_lsi = corpora.MmCorpus('./data/corpustrain_lsi.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(corpustrain_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simlist = give_similar_talks(152,5,corpustrain_lsi,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(127, 0.91849649),\n",
       " (91, 0.88651842),\n",
       " (157, 0.85837495),\n",
       " (330, 0.84537607),\n",
       " (2114, 0.83207947)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "1. Topic modeling is done with LSI, the results are so far satisfactory, especially with the transcripts. The draw back is the interpretation\n",
    "2. The results are saved in the ./data folder, both the models and the transformed corpuses, should be able to directly load in for rating prediction\n",
    "3. Models and corpuses with different number of topics (20,25,30,40,50) were saved and can be used as hyparameter to tune when doing k-nn rating prediction\n",
    "3. Test set transcripts and speaker backgrounds should be transformed using the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
